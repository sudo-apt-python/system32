{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Name:** Aniket Bapusaheb Labade\n",
        "\n",
        "**PRN No.:** RBT21CB012\n",
        "\n",
        "**Subject:** Machine Learning\n",
        "\n",
        "**Practical No. 6** Comparitive Analysis of all ensemble techniques.:\n",
        "\n",
        "\n",
        "**AdaBoost:**\n",
        "AdaBoost is an ensemble learning method that combines multiple weak classifiers to create a strong classifier, with a focus on improving the performance of misclassified instances in each iteration.\n",
        "\n",
        "**XGBoost:**\n",
        "XGBoost is an efficient and scalable gradient boosting framework that uses tree-based models, employing a regularization term to control model complexity and a unique algorithm for parallel and distributed computing.\n",
        "\n",
        "**CatBoost:**\n",
        "CatBoost is a gradient boosting algorithm designed for categorical feature support, automatically handling categorical variables without preprocessing and employing techniques like ordered boosting for enhanced accuracy.\n",
        "\n",
        "**Gradient Boosting:**\n",
        "Gradient Boosting is a general ensemble learning technique that builds a series of weak learners sequentially, each correcting the errors of its predecessor by minimizing a differentiable loss function through gradient descent."
      ],
      "metadata": {
        "id": "aoe6xrG2Nt2J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_6AHVVtBAiq"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "D_EZCToPBjxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "metadata": {
        "id": "GlEOVnIZBoqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abc = AdaBoostClassifier(n_estimators=50,\n",
        "                         learning_rate=1)\n",
        "\n",
        "model = abc.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "DQbjzcyuBvLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlfVn_qiByXG",
        "outputId": "6452bf0c-d0f2-4d8f-a6c3-204a3e77f957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_digits\n",
        "gbc = GradientBoostingClassifier(n_estimators=300,\n",
        "                                 learning_rate=0.05,\n",
        "                                 random_state=100,\n",
        "                                 max_features=5 )\n",
        "\n",
        "gbc.fit(X_train, y_train)\n",
        "pred_y = gbc.predict(X_test)\n",
        "acc = accuracy_score(y_test, pred_y)\n",
        "print(\"Gradient Boosting Classifier accuracy is : {:.2f}\".format(acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwq0mfRBCGA_",
        "outputId": "d63cad16-a363-496a-c630-d998a969efc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Classifier accuracy is : 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy pandas scikit-learn xgboost catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GguLeKUHPG5",
        "outputId": "5c2c23b4-232e-44a0-93d8-a6aba197b761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "iris = load_iris()\n",
        "X1 = iris.data\n",
        "y = iris.target\n",
        "\n",
        "np.random.seed(42)\n",
        "a = np.random.normal(0, 0.5, X1.shape)\n",
        "X = X1 + a\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "k = 2\n",
        "selector = SelectKBest(f_classif, k=k)\n",
        "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
        "X_test_selected = selector.transform(X_test_scaled)\n",
        "\n",
        "adaboost_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "adaboost_grid_search = GridSearchCV(AdaBoostClassifier(), adaboost_param_grid, cv=3)\n",
        "adaboost_grid_search.fit(X_train_selected, y_train)\n",
        "best_adaboost_model = adaboost_grid_search.best_estimator_\n",
        "best_adaboost_pred = best_adaboost_model.predict(X_test_selected)\n",
        "best_adaboost_accuracy = accuracy_score(y_test, best_adaboost_pred)\n",
        "\n",
        "xgboost_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5]\n",
        "}\n",
        "\n",
        "xgboost_grid_search = GridSearchCV(XGBClassifier(), xgboost_param_grid, cv=3)\n",
        "xgboost_grid_search.fit(X_train_selected, y_train)\n",
        "best_xgboost_model = xgboost_grid_search.best_estimator_\n",
        "best_xgboost_pred = best_xgboost_model.predict(X_test_selected)\n",
        "best_xgboost_accuracy = accuracy_score(y_test, best_xgboost_pred)\n",
        "\n",
        "catboost_param_grid = {\n",
        "    'iterations': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "catboost_grid_search = GridSearchCV(CatBoostClassifier(silent=True), catboost_param_grid, cv=3)\n",
        "catboost_grid_search.fit(X_train_selected, y_train)\n",
        "best_catboost_model = catboost_grid_search.best_estimator_\n",
        "best_catboost_pred = best_catboost_model.predict(X_test_selected)\n",
        "best_catboost_accuracy = accuracy_score(y_test, best_catboost_pred)\n",
        "\n",
        "gradientboost_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5]\n",
        "}\n",
        "\n",
        "gradientboost_grid_search = GridSearchCV(GradientBoostingClassifier(), gradientboost_param_grid, cv=3)\n",
        "gradientboost_grid_search.fit(X_train_selected, y_train)\n",
        "best_gradientboost_model = gradientboost_grid_search.best_estimator_\n",
        "best_gradientboost_pred = best_gradientboost_model.predict(X_test_selected)\n",
        "best_gradientboost_accuracy = accuracy_score(y_test, best_gradientboost_pred)\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Model': ['AdaBoost', 'XGBoost', 'CatBoost', 'Gradient Boosting'],\n",
        "    'Accuracy': [best_adaboost_accuracy, best_xgboost_accuracy, best_catboost_accuracy, best_gradientboost_accuracy]\n",
        "})\n",
        "\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xBuoPu7G_yV",
        "outputId": "4b8db81d-ca6b-4180-8793-3cc4c25b5fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Model  Accuracy\n",
            "0           AdaBoost  0.800000\n",
            "1            XGBoost  0.900000\n",
            "2           CatBoost  0.866667\n",
            "3  Gradient Boosting  0.900000\n"
          ]
        }
      ]
    }
  ]
}